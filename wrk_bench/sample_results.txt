Here are some sample benchmark results for tests done against the trivial web servers in python3, golang, nodejs, ...

Specs:
- Ryzen 2700X stock.
- Ubuntu 18.04, kernel 5.3
- Node v12
- golang 1.12
- Not 100% sure about memory Latency, but I am guessing its no worse than around 70-80ns as these are gaming UDIMMs.
not the best kit ever, but obviously far better than server RDIMM or LRDIMMs. Still I dont think makes that much of a 
diff, as these programs are so small they all fit in cache.


# ======================================================================================================================
# ======================================================================================================================
# ======================================================================================================================
# ======================================================================================================================
# ======================================================================================================================
# ======================================================================================================================
# ======================================================================================================================
# ======================================================================================================================
# ======================================================================================================================
# ======================================================================================================================
# ======================================================================================================================
# ======================================================================================================================
# ======================================================================================================================
# ======================================================================================================================
# ======================================================================================================================
# ======================================================================================================================
# =========================================================== config: 16 thread, 400 conns, trivial servers.


# ======================================================================================================================
# =============================================================================================================== nodejs
# ======================================================================================================================
# ============================================================================================= 22k req/s - nodejs based
# trivial web server in nodejs using the http package.
# its async, but no real multi-core benefit.

Running 10s test @ http://localhost:7081
  16 threads and 400 connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency    18.05ms    2.51ms 254.95ms   95.43%
    Req/Sec     1.38k   296.17    11.45k    97.64%
  221127 requests in 10.07s, 37.12MB read
Requests/sec:  21952.51
Transfer/sec:      3.68MB


# ======================================================================================================================
# =============================================================================================================== golang
# ======================================================================================================================
# =========================================================================================== 265k req/s - golang based:
# trivial web server in golang using the http and gorilla/mux packages. (16 threads, all nearly max out in this test)


Running 10s test @ http://localhost:7081
  16 threads and 400 connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency     1.81ms    2.07ms 209.13ms   89.34%
    Req/Sec    16.84k     2.64k   46.43k    72.91%
  2671422 requests in 10.08s, 323.55MB read
Requests/sec: 265031.57
Transfer/sec:     32.10MB



# ======================================================================================================================
# =============================================================================================================== python
# ======================================================================================================================
# really only cheroot, tornado are worth considering IMO, monkey_patch seems really crazy, hacks around
# "thread local" global variables to request, response (inside user space implemented lightweight threads no less)
# look even more ugly to me.
#
# - cheroot is production ready enof to be innternet facing w/- anything else in front. at least supposed to be.
# - tornado is the most popular of them, developed at facebook. Its not WSGI tho. (which cant be said to be a liability)
# Tornado is absolutely great for long polling. If you need to emulate a push service at the application layer,
# for sure, this is going to be hard to beat. (TODO compare against even golang in this case.)
#
# - Long polling reminder: it was the one where we did a simple request/response, but the server response
# latency wasnt a few milliseconds, it was like 5 minutes. Server responded if it had a notification in 5 those minutes
# or both sides moved on. and client made sure there was a new request every 5 min.


# ======================================================================================================================
# ================================================================================================ Tornado 6 + Python3.6
# Uusing near 80-90% ish of one CPU core. As tornado has 1 thread per process.

$ wrk -c 400 -d10s -t 16 http://localhost:8082/

Running 10s test @ http://localhost:8082/
  16 threads and 400 connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   144.06ms  103.75ms   1.19s    97.37%
    Req/Sec   192.40     76.21   505.00     82.67%
  30019 requests in 10.06s, 5.93MB read
Requests/sec:   2983.70
Transfer/sec:    603.15KB

# less connections, makes latency better.
$ wrk -c 40 -d10s -t 16 http://localhost:8082/

Running 10s test @ http://localhost:8082/
  16 threads and 40 connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency    10.16ms  843.67us  22.03ms   79.32%
    Req/Sec   197.57     13.34   222.00     62.50%
  31495 requests in 10.01s, 6.22MB read
Requests/sec:   3147.23
Transfer/sec:    636.21KB


# ======================================================================================================================
# ====================================================================================================== python3/cheroot
# python3, cheroot, bottle, nothing being logged per request:
# no do_compute()


Running 10s test @ http://localhost:7081
  16 threads and 400 connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency    27.98ms  134.61ms   1.87s    97.37%
    Req/Sec   102.28    104.03     0.91k    87.56%
  11387 requests in 10.08s, 1.63MB read
  Socket errors: connect 0, read 2345, write 0, timeout 20
Requests/sec:   1129.50
Transfer/sec:    165.45KB




# ======================================================================================================================
# ============================================================================================================== Useless
# ======================================================================================================================


# ======================================================================================================================
# =============================================================================================================== bjoern
# TODO test bjoern (its supposed be a fast one written in C) fast it might be, but I dont know what shape it is in.
# from bjoern import run
# run(wsgi_app, "0.0.0.0", 8082)



# ======================================================================================================================
# ======================================================================================================= python3/gevent
# -------------------- wse_gevent.py
# python3, bottle, monkey patch gevent, one line logged per request):
# no do_compute()

Running 10s test @ http://localhost:7081
  16 threads and 400 connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   201.57ms  265.40ms   1.50s    80.33%
    Req/Sec   501.59    513.69     4.10k    84.81%
  58317 requests in 10.06s, 7.07MB read
  Socket errors: connect 0, read 0, write 0, timeout 67
Requests/sec:   5794.45
Transfer/sec:    718.88KB


# ======================================================================================================================
# ======================================================================================================= python3/gevent
# -------------------- wse_gevent.py
# python3, bottle, monkey patch gevent, logs redirected to dev/null):
# no do_compute()

Running 10s test @ http://localhost:7081
  16 threads and 400 connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   231.05ms  311.47ms   1.79s    80.68%
    Req/Sec   617.06    734.90     4.48k    86.62%
  63450 requests in 10.10s, 7.69MB read
  Socket errors: connect 0, read 0, write 0, timeout 50
Requests/sec:   6282.44
Transfer/sec:    779.35KB



# ======================================================================================================================
# ===================================================================================================== python3/gunicorn
# -------------------- wse_gunc.py
# python3, no longs, no do_compute()

# -------------------------- 16 workers

wrk -t 16 -c 400 -d 10 http://localhost:7081
Running 10s test @ http://localhost:7081
  16 threads and 400 connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency     6.74ms   34.20ms 834.62ms   97.84%
    Req/Sec     2.98k     1.18k    6.39k    69.45%
  474222 requests in 10.06s, 72.36MB read
Requests/sec:  47159.07
Transfer/sec:      7.20MB

# -------------------------- 8 workers

Running 10s test @ http://localhost:7081
  16 threads and 400 connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency    27.03ms  139.50ms   1.69s    96.78%
    Req/Sec     1.38k     1.12k    5.57k    77.18%
  218855 requests in 10.10s, 33.40MB read
Requests/sec:  21668.81
Transfer/sec:      3.31MB

# -------------------------- 4 workers 
Running 10s test @ http://localhost:7081
  16 threads and 400 connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency    27.04ms  114.04ms   1.69s    95.96%
    Req/Sec     1.07k     0.90k    3.88k    65.12%
  155164 requests in 10.10s, 23.68MB read
  Socket errors: connect 0, read 0, write 0, timeout 25
Requests/sec:  15366.83
Transfer/sec:      2.34MB

# -------------------------- 2 workers (most likely EC2 for web server)

Running 10s test @ http://localhost:7081
  16 threads and 400 connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency    23.03ms   79.39ms   1.68s    97.43%
    Req/Sec   808.32    647.15     2.12k    51.12%
  78974 requests in 10.08s, 12.05MB read
  Socket errors: connect 0, read 0, write 0, timeout 3
Requests/sec:   7837.62
Transfer/sec:      1.20MB

# -------------------------- 1 worker, why bother with gunicorn ??

Running 10s test @ http://localhost:7081
  16 threads and 400 connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency    45.87ms  100.86ms   1.66s    94.15%
    Req/Sec   389.50    365.93     1.14k    68.18%
  44373 requests in 10.07s, 6.77MB read
  Socket errors: connect 0, read 0, write 0, timeout 4
Requests/sec:   4406.60
Transfer/sec:    688.57KB




# ======================================================================================================================
# ======================================================================================================================
# ======================================================================================================================
# ======================================================================================================================
# ======================================================================================================================
# ======================================================================================================================
# ======================================================================================================================
# ======================================================================================================================
# ======================================================================================================================
# ======================================================================================================================
# ======================================================================================================================
# ======================================================================================================================
# ======================================================================================================================
# ======================================================================================================================
# ======================================================================================================================
# ======================================================================================================================
# ==================================================================== 180 req/s ~ python3 with the do_compute function:
# -------------------- wse_cheroot.py
# python3, cheroot, bottle, nothing being logged per request.:
# w/ do_compute, count from 0 to 90k


Running 10s test @ http://localhost:7081
  16 threads and 400 connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   145.56ms  208.30ms   1.90s    93.80%
    Req/Sec    22.77     15.64    90.00     70.87%
  1800 requests in 10.08s, 264.08KB read
  Socket errors: connect 0, read 404, write 0, timeout 26
Requests/sec:    178.52
Transfer/sec:     26.19KB


# ======================================================================================================================
# =========================================================================================== 300 req/s ~ python3 based:
# -------------------- wse_gevent.py
# python3, bottle, monkey patch gevent, one line logged per request):
# w/ do_compute, count from 0 to 90k

Running 10s test @ http://localhost:7081
  16 threads and 400 connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   237.28ms  506.79ms   1.95s    87.31%
    Req/Sec    52.23     51.79   320.00     88.61%
  3051 requests in 10.09s, 378.62KB read
  Socket errors: connect 0, read 0, write 0, timeout 711
Requests/sec:    302.47
Transfer/sec:     37.54KB


# ======================================================================================================================
# ======================================================================================================================
# -------------------- wse_gunc.py
# python3, gunicorn, no bottle. just wsgi app. 4 workers, ran inside a docker container. it does spike a few CPUs
# w/ do_compute, count from 0 to 90k
# gunicorn -b 0.0.0.0:7081 -w 4 wse_gunc:ws

Running 10s test @ http://localhost:7081
  16 threads and 400 connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   135.40ms   65.88ms   1.79s    96.40%
    Req/Sec    75.62     66.65   252.00     73.92%
  10037 requests in 10.07s, 1.53MB read
  Socket errors: connect 0, read 0, write 0, timeout 2
Requests/sec:    996.30
Transfer/sec:    155.67KB

# ======================================================================================================================
# ======================================================================================================================
# -------------------- wse_gunc.py
# python3, gunicorn, no bottle. just wsgi app. 4 workers, ran inside a docker container.
# it spikes all CPUs, to absolute 100%. to the point, mouse movement gets laggy. still no more than 2500 req/s
# w/ do_compute, count from 0 to 90k
# gunicorn -b 0.0.0.0:7081 -w 16 wse_gunc:ws

Running 10s test @ http://localhost:7081
  16 threads and 400 connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency    72.15ms   94.42ms   1.73s    96.28%
    Req/Sec   158.94     84.10   440.00     67.97%
  24971 requests in 10.10s, 3.81MB read
  Socket errors: connect 0, read 0, write 0, timeout 11
Requests/sec:   2471.59
Transfer/sec:    386.19KB


# ======================================================================================================================
# ======================================================================================================================
# ======================================================================================================================
# ======================================================================================================================
# ======================================================================================================================
# ======================================================================================================================
# ======================================================================================================================
# ======================================================================================================================
# ======================================================================================================================
# ======================================================================================================================
# ======================================================================================================================
# ======================================================================================================================
# ======================================================================================================================
# ======================================================================================================================
# ======================================================================================================================
# ======================================================================================================================


