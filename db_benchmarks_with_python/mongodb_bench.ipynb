{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import subprocess as sp\n",
    "import json\n",
    "import random\n",
    "import time\n",
    "import hashlib\n",
    "import base64\n",
    "from contextlib import closing\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "import pymongo\n",
    "from pymongo import MongoClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# mongodb instance. there are. (bionic is ub 18)\n",
    "# 4.2-bionic\n",
    "# 4.4-bionic\n",
    "# bionic           (as of oct 2020 this would be 4.4-bionic)\n",
    "\n",
    "# args to the entrypoint do get passed to mongod, refer to mongod manual or --help to see options\n",
    "\n",
    "# unlike pg, mdb which default their main buffer to 128MB, mongodb will go big (50% of physical RAM).\n",
    "# you can set it using: --wiredTigerCacheSizeGB 4\n",
    "# --port to set listen port (default 27017)\n",
    "\n",
    "\n",
    "docker run --rm -it --name mng44 --cpus 8 --network host \\\n",
    "-e MONGO_INITDB_ROOT_USERNAME=mongoadmin -e MONGO_INITDB_ROOT_PASSWORD=mobz1234 \\\n",
    "mongo:4.4-bionic --port 4017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to mongodb\n",
    "mng_client = MongoClient(\"mongodb://mongoadmin:mobz1234@127.0.0.1:4017\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve/connect/create a database called admin\n",
    "admin_db = mng_client.admin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database(MongoClient(host=['127.0.0.1:4017'], document_class=dict, tz_aware=False, connect=True), 'admin')\n",
      "Database(MongoClient(host=['127.0.0.1:4017'], document_class=dict, tz_aware=False, connect=True), 'bilakh')\n"
     ]
    }
   ],
   "source": [
    "print(admin_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.4.1\n"
     ]
    }
   ],
   "source": [
    "# send a serverStatus command\n",
    "res = admin_db.command(\"serverStatus\")\n",
    "# pprint(res)\n",
    "print(res['version'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate sample "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mariadb INT type is ranged: -2 147 483 648 to 2 147 483 647\n",
    "def get_random_int32():\n",
    "    tmp = 2 * 1000 * 1000 * 1000\n",
    "    return random.randint(0, tmp)\n",
    "\n",
    "def get_random_int64():\n",
    "    tmp = 80 * 1000 * 1000 * 1000 * 1000\n",
    "    return random.randint(0, tmp)\n",
    "\n",
    "def get_random_str(str_len=48):\n",
    "    assert isinstance(str_len, int)\n",
    "    assert str_len < 8192\n",
    "\n",
    "    _ = os.urandom(64)  # throw away 64 bytes\n",
    "    return base64.b64encode(os.urandom(str_len), altchars=b\"AZ\").decode('ascii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('YLZw0H5AgSUe9VuKAQ5CyElIotxGgN2zsJlv9VYHviJCAGiV7ZDc4CohlnjNaZK5', 971945541)\n",
      "('ZKHU6CGiyFML0JZi73MDQQAMHpoaweJ7x5sJPz3OLHZOLfknH7Eh5yHF09PmlKzt', 1875827613)\n",
      "('HgozIpTMTkrBNZkYpyIXiyoh0ZP5KLtOk545GAZp09axiR5iwRZ8WiqLNMvrn4EY', 716045279)\n",
      "('ht2beAnAR9U0E2NgoAmSTsGJvUHyyGm0bXb8V4rChMBMxDkovW1hfsHdYvUHHdAc', 852592087)\n",
      "('ZHnypkV8wX8BZeE51JSGBwI2Z3ckmYPQoVvumdJydib8mtJEPUc8vCCMh65vhiww', 150396138)\n"
     ]
    }
   ],
   "source": [
    "tmp_table = []\n",
    "for _ in range(5):\n",
    "    tmp_table.append((get_random_str(48), get_random_int32()))\n",
    "\n",
    "for row in tmp_table:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "| rdbms concept   |    MongoDB equivalent  |\n",
    "|:----------------|:----------------------:|\n",
    "|  Database       |  Database              |\n",
    "|  table          |  Collections           |\n",
    "|  rows           |  Documents             |\n",
    "|  index          |  Index                 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new database\n",
    "bench_ntbk_db = mng_client.bench_ntbk\n",
    "print(bench_ntbk_db) # rdy for CRUD operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertOneResult at 0x7f82b52eabc8>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a collection (table) called xb_bench\n",
    "# put a document (row) in it\n",
    "\n",
    "bench_ntbk_db.xb_bench.insert_one({\n",
    "    \"name\": \"bobz\",\n",
    "    \"pw_shadow\": get_random_str(40),\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bench_ntbk_db.xb_bench.count_documents({'name': 'jack'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bench_ntbk_db.xb_bench.count_documents({'name': 'bobz'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bench_ntbk_db.xb_bench.count_documents({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sample_collec(num_docs):\n",
    "    tmp_collec = []\n",
    "    for _ in range(num_docs):\n",
    "        doc = {}\n",
    "        doc['name'] = random.choice(['bobz', 'jack', 'dave', 'mira', 'bilakh', 'khotmek', 'suduk', 'grass', 'steam'])\n",
    "        doc['pw_shadow'] = get_random_str(36)\n",
    "        tmp_collec.append(doc)\n",
    "    \n",
    "    print(\"generate_sample_collec done ...\")\n",
    "    return tmp_collec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate_sample_collec done ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'name': 'suduk',\n",
       " 'pw_shadow': 'BOoABFPoiIwrfpL0zBxuuLh8kqTEdm8JbONxdwHnEHcAHfAB'}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_collec = generate_sample_collec(20*1000)\n",
    "tmp_collec[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate_sample_collec done ...\n",
      "time: 5.83831907401327\n",
      "ips: 3425.6435365140064\n",
      "\n",
      "Actual count: 680002\n"
     ]
    }
   ],
   "source": [
    "num_docs = 20 * 1000\n",
    "tmp_collec = generate_sample_collec(num_docs)\n",
    "\n",
    "# *** start timer\n",
    "start_time = time.perf_counter()\n",
    "for doc in tmp_collec:\n",
    "    bench_ntbk_db.xb_bench.insert_one(doc)\n",
    "\n",
    "# stop time\n",
    "elapsed_time = time.perf_counter() - start_time\n",
    "\n",
    "print(f\"time: {elapsed_time}\")\n",
    "print(f\"ips: {num_docs/elapsed_time}\")\n",
    "\n",
    "actual_count = bench_ntbk_db.xb_bench.count_documents({})\n",
    "print(f\"\\nActual count: {actual_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate_sample_collec done ...\n",
      "time: 8.877478927955963\n",
      "ips: 90115.67433640755\n",
      "\n",
      "Actual count: 2280002\n"
     ]
    }
   ],
   "source": [
    "num_docs = 800 * 1000\n",
    "tmp_collec = generate_sample_collec(num_docs)\n",
    "\n",
    "# *** start timer\n",
    "start_time = time.perf_counter()\n",
    "bench_ntbk_db.xb_bench.insert_many(tmp_collec)\n",
    "elapsed_time = time.perf_counter() - start_time\n",
    "\n",
    "print(f\"time: {elapsed_time}\")\n",
    "print(f\"ips: {num_docs/elapsed_time}\")\n",
    "\n",
    "actual_count = bench_ntbk_db.xb_bench.count_documents({})\n",
    "print(f\"\\nActual count: {actual_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "|          method           |   document ips    |\n",
    "|:--------------------------|:-----------------:|\n",
    "| insert_one                |       3500        |\n",
    "| insert_many               |     75k-91k       |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### conclusion notes"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# ----- insert_one() perf is comparable to regular execute against pg/mariadb\n",
    "which proves the point I had about using pg/mariadb, actually its quite a bit less.\n",
    "\n",
    "Thats cause we shouldnt compare 3500 to 900/800 (which was pg/mdb perf for sync single execute() calls)\n",
    "that would seem its about 4x better than mariadb/pg, but pg/mdb do 10x better if sync is off.\n",
    "\n",
    "ACID means they default to sync. Mongo which promised no such thing doesnt default to sync.\n",
    "No way mongo is issuing fsync() calls for each insert_one(). They never said ACID.\n",
    "Yes they said, single CRUD is supposed to be atomic, but atomic is not ACID. D stands for durable.\n",
    "mongo likely is atomic for single CRUD, but that can be done from memory or disk. when its flushed to disk\n",
    "it goes through a journal and does it atomically, all or none.\n",
    "Still no reason for insert_one() to go issue fsync() calls.\n",
    "\n",
    "# ----- The documents that actually get written are larger than what we sent out. they get id, hashes, timestamp,\n",
    "date, ...a much bigger json is being saved. the overhead feels much larger than a rdbms table. Could be the\n",
    "replica set/sharding features require extra overhead even if not using them. But it rly feels like more overhead\n",
    "if you watch the logs as you are inserting, and that explains why 8-10k non sync insertion rate we had in pg/mdb\n",
    "is cut down to half in mongo.\n",
    "\n",
    "# ----- insert_many() number just validated my thoughts.\n",
    "there is no way it can get to 75k to 91k w/- leaving sync for later.\n",
    "also the spike in CPU usage pattern confirms this. when I insert many 800k records\n",
    "memory consumption grows 100MB ish, cpu grows as its growing memory. then there is a\n",
    "few seconds of 0 cpu, then a short spike, and back to zero. highly likely thats the sync call.\n",
    "memory stays 100MB higher which makes sense if buffer is 50% of total test system (that would be 16 GB)\n",
    "so no need to evict even after syncd to disk.\n",
    "\n",
    "# ----- conclusions about mongo:\n",
    "- We lost ACID, not even available for metadata tables.\n",
    "- insert_many() benched 20%-30% worse than pg/mariadb w/ sync later even for CRUD operations.\n",
    "- insert_one()  benched 2x worse than pg/mariadb w/ sync later even for CRUD operations.\n",
    "- pg/mdb is better, way beter, even at mongodb's game.\n",
    "\n",
    "- no types/datatypes available. No constraints on values or types. Just JSON documents.\n",
    "- No database trigger functionality officially.\n",
    "- Stored procedures dont really exist either, at least officially.\n",
    "It is possible to do some basic javascript functions but I highly doubt you can import node system libs,\n",
    "and do things like fire off requests or spawn workers. and definitely not plpython3u.\n",
    "there is some map reduce stuff, but even that they are saying is slower than aggregation constructs offered in\n",
    "recent mongo versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# for reference this was mariadb 10.5\n",
    "\n",
    "\n",
    "|                insertion method                  |   ips (pymysql)   |   ips (mariadb)   |\n",
    "|:-------------------------------------------------|:-----------------:|:-----------------:|\n",
    "| regular execute                                  |       820         |     820 (+10 ??)  |\n",
    "| regular execute, no sync                         |         8 K       |         8 K       |\n",
    "| executemany                                      |       102 K       |       106 K       |\n",
    "| executemany,     no sync                         |       101 K       |       104 K       |\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# for reference this was pg 13\n",
    "\n",
    "\n",
    "|                insertion method                  |   ips (psycopg2)  |\n",
    "|:-------------------------------------------------|:-----------------:|\n",
    "| regular execute                                  |    900            |\n",
    "| executemany (uses prep stmnt)                    |    890            |\n",
    "| regular execute, no sync                         |    11k            |\n",
    "| psycopg2.extras.execute_values                   |    45k            |\n",
    "| psycopg2.extras.execute_values no sync           |    100k           |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python36964bit6486db22bd404319aca96f84d42312c3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
