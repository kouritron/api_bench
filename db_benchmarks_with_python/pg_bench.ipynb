{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import subprocess as sp\n",
    "import json\n",
    "import random\n",
    "import time\n",
    "import hashlib\n",
    "import base64\n",
    "from contextlib import closing\n",
    "\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "\n",
    "from concurrent.futures.thread import ThreadPoolExecutor\n",
    "from concurrent.futures.process import ProcessPoolExecutor\n",
    "\n",
    "import psycopg2\n",
    "import psycopg2.extras\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get a quick pg instance:\n",
    "---\n",
    "\n",
    "```bash\n",
    "# ephemeral pg13\n",
    "docker run --rm -it --name pg13 --network host -e POSTGRES_PASSWORD=bobz1234 postgres:13 --port=9932\n",
    "\n",
    "\n",
    "# put data under tmpfs\n",
    "# PGDATA tells it where to put data, needs to be someplace that can be chowned to postgres user\n",
    "# by default things should be under /var/lib/postgresql/data\n",
    "docker run --rm -it --name pg13 --network host -e POSTGRES_PASSWORD=bobz1234 \\\n",
    "-e PGDATA=/var/lib/postgresql/data/tmpfs_vol/pgdata --tmpfs /var/lib/postgresql/data/tmpfs_vol/ postgres:13 --port=9932\n",
    "\n",
    "\n",
    "# if connecting from remote add\n",
    "--listen-addresses='*'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# dsn = \"... dbname=postgres options='-c synchronous_commit=off'\"\n",
    "_PG_DSN_SYNC = {\n",
    "    # \"host\": \"192.168.24.141\",\n",
    "    # \"port\": \"5432\",\n",
    "    \n",
    "    \"host\": \"127.0.0.1\",\n",
    "    \"port\": \"9932\",\n",
    "    \n",
    "    \"database\": \"postgres\",\n",
    "    \"user\": \"postgres\",\n",
    "    \"password\": 'bobz1234',\n",
    "    \n",
    "    # any other options should be passed along to underlying lib, but only those psycopg2 understands\n",
    "    # and accepts. \"nonz\": \"hello world\" wouldnt be accepted or passed along\n",
    "    \"application_name\": \"pg_bench_ntbk\",\n",
    "}\n",
    "\n",
    "_PG_DSN_NO_SYNC = _PG_DSN_SYNC.copy() # shallow is enof.\n",
    "_PG_DSN_NO_SYNC[\"options\"] = \"-c synchronous_commit=off\"\n",
    "_PG_DSN_NO_SYNC[\"application_name\"] = \"fts_ntbk_unsync\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sync_dbconn = psycopg2.connect(**_PG_DSN_SYNC)\n",
    "sync_dbconn.autocommit = True\n",
    "\n",
    "unsync_dbconn = psycopg2.connect(**_PG_DSN_NO_SYNC)\n",
    "unsync_dbconn.autocommit = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sync_cur = sync_dbconn.cursor()\n",
    "unsync_cur = unsync_dbconn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# common q exec.\n",
    "def exec_q_unsync(q, pr_res=True, col_names=True):\n",
    "    with closing(unsync_dbconn.cursor()) as tmp_cur:\n",
    "        tmp_cur.execute(q)\n",
    "        if pr_res:\n",
    "            if col_names:\n",
    "                print(\"|\".join([desc[0] for desc in tmp_cur.description]))\n",
    "            print('-'*40)\n",
    "            for row in tmp_cur.fetchall():\n",
    "                print(row)\n",
    "            # sep\n",
    "            print(\"\")\n",
    "# sync\n",
    "def exec_q_sync(q, pr_res=True, col_names=True):\n",
    "    with closing(sync_dbconn.cursor()) as tmp_cur:\n",
    "        tmp_cur.execute(q)\n",
    "        if pr_res:\n",
    "            if col_names:\n",
    "                print(\"|\".join([desc[0] for desc in tmp_cur.description]))\n",
    "            print('-'*40)\n",
    "            for row in tmp_cur.fetchall():\n",
    "                print(row)\n",
    "            # sep\n",
    "            print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run some test queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "synchronous_commit\n",
      "----------------------------------------\n",
      "('on',)\n",
      "\n",
      "synchronous_commit\n",
      "----------------------------------------\n",
      "('off',)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "exec_q_sync(\"SHOW synchronous_commit;\")\n",
    "exec_q_unsync(\"SHOW synchronous_commit;\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate sample "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mariadb INT type is ranged: -2 147 483 648 to 2 147 483 647\n",
    "def get_random_int32():\n",
    "    tmp = 2 * 1000 * 1000 * 1000\n",
    "    return random.randint(0, tmp)\n",
    "\n",
    "def get_random_int64():\n",
    "    tmp = 80 * 1000 * 1000 * 1000 * 1000\n",
    "    return random.randint(0, tmp)\n",
    "\n",
    "def get_random_str(str_len=48):\n",
    "    assert isinstance(str_len, int)\n",
    "    assert str_len < 8192\n",
    "\n",
    "    return base64.b64encode(os.urandom(str_len), altchars=b\"AZ\").decode('ascii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('SHiKQb2PtvEJFmomPtQjXzhbZqrMdTXFwLL5XcwenZzfr4tk86W9vFmIk2pzxsjD', 622804870)\n",
      "('mKwRXmoddUqnAo1GqS0bwIVZ29xSKcqfNdlNoSd7YaJ7ZTgkWWMfpwyKbuDLpXRN', 1615188628)\n",
      "('6K4CQ3cAwI44uAXmgV4wDzr2iErcBmCAK7Q4Hq7PEqvvpZsAW4TE5Vb9vExYMfQi', 1442077397)\n",
      "('o2P5cIkHrxArO1w9W9JqtCthpsi0Al0mCMVWrAZqUQdle7xxwHlUAFgO2l4E2wkQ', 909154400)\n",
      "('EZZ9ESdzayTlPwy06egJCROxqehi9pipkLj3cFPTeaL0re6cieA5OV6T9d0sUuQC', 1433974176)\n"
     ]
    }
   ],
   "source": [
    "tmp_table = []\n",
    "for _ in range(5):\n",
    "    tmp_table.append((get_random_str(48), get_random_int32()))\n",
    "\n",
    "for row in tmp_table:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len('Q8M5rzhQveJJClZAGhXtNmWCgRm2ETnSeZb2KdXy1vDVlnj3tYOlOZulh2Fc7T1p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create BENCHMARK tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "refresh_schema_q = \"\"\"\n",
    "DROP TABLE IF EXISTS xb_bench1 CASCADE;\n",
    "DROP TABLE IF EXISTS xb_bench2 CASCADE;\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS xb_bench1(\n",
    "brid SERIAL PRIMARY KEY NOT NULL,\n",
    "val_1 TEXT,\n",
    "num_1 BIGINT);\n",
    "\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS xb_bench2(\n",
    "brid SERIAL PRIMARY KEY NOT NULL,\n",
    "val_1 TEXT,\n",
    "num_1 BIGINT);\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "exec_q_sync(refresh_schema_q, pr_res=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test insert some records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"\"\" INSERT INTO xb_bench1(val_1, num_1) VALUES \n",
    "('Q8M5rzhQveJJClZAGhXtNmWCgRm2ETnSeZb2KdXy1vDVlnj3tYOlOZulh2Fc7T1p', '2120724'),\n",
    "('Q8M5rzhQveJJClZAGhXtNmqCgRm2ETnSeZb2KdXy3vDVlnj3tYOlOZulh2Fv7T1p', '2020921');\n",
    "\"\"\"\n",
    "\n",
    "sync_cur.execute(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "brid|val_1|num_1\n",
      "----------------------------------------\n",
      "(1, 'Q8M5rzhQveJJClZAGhXtNmWCgRm2ETnSeZb2KdXy1vDVlnj3tYOlOZulh2Fc7T1p', 2120724)\n",
      "(2, 'Q8M5rzhQveJJClZAGhXtNmqCgRm2ETnSeZb2KdXy3vDVlnj3tYOlOZulh2Fv7T1p', 2020921)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "exec_q_sync(\"select * from xb_bench1;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"INSERT INTO xb_bench1(val_1, num_1) VALUES (%s, %s);\"\n",
    "record = ('onuqwddqobqubffqubf', 13400111)\n",
    "sync_cur.execute(q, record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "brid|val_1|num_1\n",
      "----------------------------------------\n",
      "(1, 'Q8M5rzhQveJJClZAGhXtNmWCgRm2ETnSeZb2KdXy1vDVlnj3tYOlOZulh2Fc7T1p', 2120724)\n",
      "(2, 'Q8M5rzhQveJJClZAGhXtNmqCgRm2ETnSeZb2KdXy3vDVlnj3tYOlOZulh2Fv7T1p', 2020921)\n",
      "(3, 'onuqwddqobqubffqubf', 13400111)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "exec_q_sync(\"select * from xb_bench1;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "exec_q_sync(refresh_schema_q, pr_res=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "brid|val_1|num_1\n",
      "----------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "exec_q_sync(\"select * from xb_bench1;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BENCHMARK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample data rdy ...\n",
      "time: 3.4433179199986625\n",
      "ips: 11616.702532078576\n",
      "\n",
      "Actual count(*): (40000,)\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------- sync execute\n",
    "num_records = 40 * 1000\n",
    "\n",
    "# drop tables and start fresh\n",
    "tmp_cur = sync_dbconn.cursor()\n",
    "tmp_cur.execute(refresh_schema_q)\n",
    "\n",
    "# sample data\n",
    "tmp_table = []\n",
    "for _ in range(num_records):\n",
    "    tmp_table.append((get_random_str(48), get_random_int32()))\n",
    "\n",
    "print(\"sample data rdy ...\")\n",
    "\n",
    "# query\n",
    "q = \"INSERT INTO xb_bench1(val_1, num_1) VALUES (%s, %s);\"\n",
    "\n",
    "# *** time insertion\n",
    "start_time = time.perf_counter()\n",
    "for record in tmp_table:\n",
    "    tmp_cur.execute(q, record)\n",
    "\n",
    "# stop time\n",
    "elapsed_time = time.perf_counter() - start_time\n",
    "\n",
    "print(f\"time: {elapsed_time}\")\n",
    "print(f\"ips: {num_records/elapsed_time}\")\n",
    "\n",
    "tmp_cur.execute(\"select count(*) from xb_bench1;\")\n",
    "print(f\"\\nActual count(*): {tmp_cur.fetchone()}\")\n",
    "\n",
    "tmp_cur.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample data rdy ...\n",
      "time: 3.4253708310134243\n",
      "ips: 11677.567765171185\n",
      "\n",
      "Actual count(*): (40000,)\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------- unsync execute\n",
    "num_records = 40 * 1000\n",
    "\n",
    "# drop tables and start fresh\n",
    "tmp_cur = unsync_dbconn.cursor()\n",
    "tmp_cur.execute(refresh_schema_q)\n",
    "\n",
    "# sample data\n",
    "tmp_table = []\n",
    "for _ in range(num_records):\n",
    "    tmp_table.append((get_random_str(48), get_random_int32()))\n",
    "\n",
    "print(\"sample data rdy ...\")\n",
    "\n",
    "# query\n",
    "q = \"INSERT INTO xb_bench1(val_1, num_1) VALUES (%s, %s);\"\n",
    "\n",
    "# *** time insertion\n",
    "start_time = time.perf_counter()\n",
    "for record in tmp_table:\n",
    "    tmp_cur.execute(q, record)\n",
    "\n",
    "# stop time\n",
    "elapsed_time = time.perf_counter() - start_time\n",
    "\n",
    "print(f\"time: {elapsed_time}\")\n",
    "print(f\"ips: {num_records/elapsed_time}\")\n",
    "\n",
    "tmp_cur.execute(\"select count(*) from xb_bench1;\")\n",
    "print(f\"\\nActual count(*): {tmp_cur.fetchone()}\")\n",
    "\n",
    "tmp_cur.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample data rdy ...\n",
      "time: 0.8536967730033211\n",
      "ips: 105423.84936442751\n",
      "\n",
      "Actual count(*): (90000,)\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------- sync fast bulk load\n",
    "num_records = 90 * 1000\n",
    "\n",
    "# drop tables and start fresh\n",
    "tmp_cur = sync_dbconn.cursor()\n",
    "tmp_cur.execute(refresh_schema_q)\n",
    "\n",
    "# sample data\n",
    "tmp_table = []\n",
    "for _ in range(num_records):\n",
    "    tmp_table.append((get_random_str(48), get_random_int32()))\n",
    "\n",
    "print(\"sample data rdy ...\")\n",
    "\n",
    "# query\n",
    "q = \"INSERT INTO xb_bench1(val_1, num_1) VALUES %s;\"\n",
    "\n",
    "# *** time insertion\n",
    "start_time = time.perf_counter()\n",
    "psycopg2.extras.execute_values(tmp_cur, q, tmp_table)\n",
    "elapsed_time = time.perf_counter() - start_time\n",
    "\n",
    "\n",
    "print(f\"time: {elapsed_time}\")\n",
    "print(f\"ips: {num_records/elapsed_time}\")\n",
    "\n",
    "tmp_cur.execute(\"select count(*) from xb_bench1;\")\n",
    "print(f\"\\nActual count(*): {tmp_cur.fetchone()}\")\n",
    "\n",
    "tmp_cur.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample data rdy ...\n",
      "time: 0.8280718580062967\n",
      "ips: 108686.21983687271\n",
      "\n",
      "Actual count(*): (90000,)\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------- unsync fast bulk load\n",
    "num_records = 90 * 1000\n",
    "\n",
    "# drop tables and start fresh\n",
    "tmp_cur = unsync_dbconn.cursor()\n",
    "tmp_cur.execute(refresh_schema_q)\n",
    "\n",
    "# sample data\n",
    "tmp_table = []\n",
    "for _ in range(num_records):\n",
    "    tmp_table.append((get_random_str(48), get_random_int32()))\n",
    "\n",
    "print(\"sample data rdy ...\")\n",
    "\n",
    "# query\n",
    "q = \"INSERT INTO xb_bench1(val_1, num_1) VALUES %s;\"\n",
    "\n",
    "# *** time insertion\n",
    "start_time = time.perf_counter()\n",
    "psycopg2.extras.execute_values(tmp_cur, q, tmp_table)\n",
    "elapsed_time = time.perf_counter() - start_time\n",
    "\n",
    "\n",
    "print(f\"time: {elapsed_time}\")\n",
    "print(f\"ips: {num_records/elapsed_time}\")\n",
    "\n",
    "tmp_cur.execute(\"select count(*) from xb_bench1;\")\n",
    "print(f\"\\nActual count(*): {tmp_cur.fetchone()}\")\n",
    "\n",
    "tmp_cur.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---\n",
    "# pc1 results\n",
    "* ryzen 2700x\n",
    "* samsung nvme 970 evo 500GB\n",
    "* 32 GB DDR4\n",
    "* Ubuntu 18.04 (bionic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### tmpfs data volume\n",
    "\n",
    "\n",
    "|                insertion method                  |   ips (dkr/pg13)   |\n",
    "|:-------------------------------------------------|:------------------:|\n",
    "| regular execute                                  |        12 K        | \n",
    "| regular execute,         no sync                 |        12 K        |\n",
    "| extras.execute_values                            |       110 K        |\n",
    "| extras.execute_values,   no sync                 |       110 K        |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---\n",
    "# Raspberry pi 3 B\n",
    "* Quad core A53\n",
    "* 128GB micro sd,\n",
    "* kernel 5.4, ubuntu server,\n",
    "* docker pg13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pgdata on tmpfs\n",
    "\n",
    "|                insertion method                  | ips (pi3/dkr/pg13) |\n",
    "|:-------------------------------------------------|:------------------:|\n",
    "| regular execute                                  |      ~ 1000        | \n",
    "| regular execute,         no sync                 |      ~ 1000        |\n",
    "| extras.execute_values                            |      ~ 15 K        |\n",
    "| extras.execute_values,   no sync                 |      ~ 15 K        |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 128GB sandisk sd card, raspberry pi 3 B \n",
    "\n",
    "\n",
    "|                insertion method                  | ips (pi3/dkr/pg13) | ips (pi3/pg11) |\n",
    "|:-------------------------------------------------|:------------------:|:--------------:|\n",
    "| regular execute                                  |     ~ 380          |   ~ same       |\n",
    "| regular execute,         no sync                 |      1200          |    950         |\n",
    "| extras.execute_values                            |         7 K        |   ~ same       |\n",
    "| extras.execute_values,   no sync                 |        16 K        |      14 K      |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# crap 8 gb kingston sd card\n",
    "\n",
    "```text\n",
    "\n",
    "|                insertion method                  | ips (pi3/dkr/pg13) |\n",
    "|:-------------------------------------------------|:------------------:|\n",
    "| regular execute                                  |       100          |\n",
    "| regular execute,         no sync                 |       800          |\n",
    "| extras.execute_values                            |       600          |\n",
    "| extras.execute_values,   no sync                 |      8 K           |\n",
    "\n",
    "Note1: w/ crap kingston sd \"exec no sync\" does better than \"sync bulk insert\" (800 vs 600)\n",
    "\"no sync bulk insert\" does 8k of course. showing how clearly kingston is the bottleneck.\n",
    "\n",
    "we are testomg raw ips, this was always testing disk in sync mode.\n",
    "its not sysbench OLTP, no lock contention or anything like that.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---\n",
    "# orange pi one:\n",
    "* allwinner H3 quad core (3 enabled) armv7lhf,\n",
    "* 512mbddr3,\n",
    "* 16gb microsd lexxar,\n",
    "* kernel 3.4, pg9.3\n",
    "* ubuntu 14 (trusty) provided by orange pi w/ custom kernel. not upstream.\n",
    "\n",
    "```text\n",
    "\n",
    "|                insertion method                  | ips (orange pi one/pg9.3) |\n",
    "|:-------------------------------------------------|:-------------------------:|\n",
    "| regular execute                                  |       ~ 200               |\n",
    "| regular execute,         no sync                 |        1500               |\n",
    "| extras.execute_values                            |         6 K               |\n",
    "| extras.execute_values,   no sync                 |        11 K               |\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python36964bit6486db22bd404319aca96f84d42312c3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
